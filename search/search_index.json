{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"","tags":["EGR314","Team 305"]},{"location":"#welcome-to-asu-egr314-2025-s-305-team-page","title":"Welcome to ASU-EGR314-2025-S-305 Team Page","text":"","tags":["EGR314","Team 305"]},{"location":"#team-members","title":"Team Members:","text":"<ul> <li>Agilan Kumar</li> <li>Andrew Rushton</li> <li>David Diaz</li> <li>Zachary Romero</li> </ul>","tags":["EGR314","Team 305"]},{"location":"#summary","title":"Summary","text":"<p>Our project focused on creating an integrated system where independent subsystems worked together through UART communication to perform a sequence of automated tasks. At the core of the design was a color sensor that detected either red or blue light. Once a color was identified, this information was transmitted via UART to a microcontroller, which then sent the data to an MQTT server. The server acted as a central hub, storing the color data and using it to determine the appropriate response. Based on the color detected, the server relayed a command over UARTto control a motor\u2019s movement.</p> <p>The motor, upon receiving the command, responded by adjusting its speed accordingly. This speed data was then sent back through UART to the microcontroller and forwarded to a Human-Machine Interface (HMI), where it was displayed for users to monitor in real time. Each part of the system, the color sensor, MQTT server, motor driver, and HMI, operated as its own functional unit, but ccummunicated through a fixed UART communication structure. This ensured reliable data exchange and coordination across the system, allowing for smooth automation from sensor input to motor control and visual feedback.</p>","tags":["EGR314","Team 305"]},{"location":"#introduction","title":"Introduction","text":"<p>Our team is dedicated to creating an innovative and impactful STEM-themed project that demonstrates technical skills, teamwork, and creativity while contributing to the development of interactive educational tools for K-12 students. By focusing on modularity, interactivity, and industry-standard practices, we aim to deliver a high-quality system that inspires curiosity and excitement for STEM concepts. Through collaborative effort and individual contributions, we seek to design, build, and document a professional-grade modular system that adheres to UART daisy chain communication protocols and supports future scalability. This report outlines our team\u2019s charter, goals, objectives, communication strategies, and responsibilities, all of which are aligned to ensure the success of our project and the professional growth of our team members. By fostering a positive and productive team environment, we strive to achieve excellence in both the technical and educational aspects of our project.</p>","tags":["EGR314","Team 305"]},{"location":"#team-charter","title":"Team Charter","text":"<p>Team Goals:</p> <ol> <li> <p>Ensure Communication Protocol Compliance: Strictly adhere to the UART daisy chain communication protocols to facilitate seamless connectivity between all subsystems.</p> </li> <li> <p>Foster Technical Excellence: Promote in-depth learning and hands-on experience in PCB design, microcontroller programming, modular integration, and embedded systems development.</p> </li> <li> <p>Create an Educational Impact: Develop an engaging STEM-themed display that effectively demonstrates scientific or engineering concepts to K-12 students, sparking curiosity and interest in STEM fields.</p> </li> <li> <p>Deliver a High-Quality Product: Design a modular system that exceeds course expectations in functionality, reliability, and presentation quality.</p> </li> <li> <p>Innovate and Inspire: Incorporate cutting-edge ideas and unique design solutions to develop a project that stands out at the Innovation Showcase.</p> </li> <li> <p>Encourage Collaboration: Maintain a strong sense of teamwork by leveraging individual strengths, sharing knowledge, and supporting one another throughout the design process.</p> </li> <li> <p>Meet Industry Standards: Design a system that follows best practices in engineering, including the use of industry-standard components, reliable circuit designs, and user-friendly interfaces.</p> </li> <li> <p>Professional Presentation: Prepare a polished project demonstration, including clear documentation, functional prototypes, and professional communication, for the Innovation Showcase.</p> </li> <li> <p>Time and Resource Management: Adhere to deadlines, stay within budget constraints, and manage team resources effectively to achieve project goals without unnecessary delays or overspending.</p> </li> <li> <p>Enhance Career Readiness: Use this project as a platform to showcase individual and team expertise, improve engineering portfolios, and gain valuable project management experience.</p> </li> </ol>","tags":["EGR314","Team 305"]},{"location":"#how-we-developed-these-goals","title":"How We Developed These Goals:","text":"<p>Our team spent time discussing individual aspirations and shared objectives. We aligned our priorities to ensure a unified approach toward success, emphasizing technical growth, collaboration, and impact on STEM education. By combining our ideas, we defined goals that reflect our commitment to learning, innovation, and professional development.</p>","tags":["EGR314","Team 305"]},{"location":"#product-mission-statement","title":"Product Mission Statement","text":"<p>Our mission is to design an engaging, innovative STEM-themed system for K-12 students that demonstrates scientific and engineering concepts through interactive, modular, and user-friendly technology. By leveraging cutting-edge communication protocols, intuitive interfaces, and a robust modular design, we aim to create an inspiring and educational experience that fosters curiosity, critical thinking, and a passion for STEM disciplines.</p>","tags":["EGR314","Team 305"]},{"location":"#objectives","title":"Objectives:","text":"<ol> <li> <p>Educational and Interactive Design: Develop a hands-on system that allows K-12 students to explore STEM concepts through active engagement and interaction. The project will incorporate real-world applications of engineering and science to provide meaningful learning experiences.</p> </li> <li> <p>Seamless Modular Integration: The system will feature individual subsystems, including sensor, actuator, HMI, and communication modules, that connect effortlessly via standardized UART daisy chain communication. Modularity will ensure ease of expansion, troubleshooting, and future improvements.</p> </li> <li> <p>Innovative and User-Friendly Interface: A Human-Machine Interface (HMI) with push buttons and an OLED screen will be implemented to provide an intuitive and engaging user experience. This interface will support real-time data visualization and system control for effective interaction.</p> </li> <li> <p>Robust Communication and Connectivity: The system will utilize reliable UART communication to ensure smooth and efficient data exchange between subsystems. Additionally, it will integrate MQTT or equivalent IoT functionality to enable bidirectional internet communication and remote monitoring or control.</p> </li> <li> <p>Professional and High-Quality Design: The project will adhere to industry-standard practices in circuit design, component selection, and software development to ensure reliability and scalability. Surface-mount technology will be employed for professional-grade PCB fabrication while meeting project specifications.</p> </li> <li> <p>STEM Engagement and Outreach: The project aims to inspire young learners to pursue STEM careers by creating a tool that meets course requirements and serves as an engaging educational resource. Creative and interactive features will make complex concepts accessible to a non-technical audience.</p> </li> <li> <p>Technical Growth and Career Development: Team members will gain hands-on experience in PCB design, microcontroller programming, and system integration. The project will also enhance engineering portfolios by showcasing innovative designs and thorough documentation, ultimately improving career readiness.</p> </li> <li> <p>Sustainability and Future Proofing: The system will be designed to support easy updates, enhancements, and potential reuse for future projects or applications. Where possible, eco-friendly components and design strategies will be utilized to ensure sustainability.</p> </li> </ol>","tags":["EGR314","Team 305"]},{"location":"#how-we-developed-this-mission","title":"How We Developed This Mission:","text":"<p>The mission statement and objectives were developed through team discussions focused on shared goals and aspirations. By combining individual insights, course requirements, and a commitment to innovation, the team defined a product vision that aims to exceed expectations and deliver a meaningful impact.</p>","tags":["EGR314","Team 305"]},{"location":"#roles-and-responsibilities","title":"Roles and Responsibilities","text":"Role Responsibility Meeting Leader Schedule and facilitate team meetings, ensure agenda is followed. Meeting Recorder Document meeting minutes, attendance, and action items. Assignment Leader Oversee assignment progress and ensure timely submission to Canvas. Project Monitor Track project progress, provide reminders for deadlines, and maintain accountability. <p>Roles will rotate bi-weekly to ensure equal participation and learning opportunities.</p>","tags":["EGR314","Team 305"]},{"location":"#communication-procedures","title":"Communication Procedures","text":"<ul> <li>Primary Communication Channels:</li> <li>Group text or Discord for quick updates.</li> <li>Email for formal documentation and sharing files.</li> <li>Meeting Schedule:</li> <li>Weekly meetings on Fridays, 4:00 PM - 6:00 PM.</li> <li>Additional meetings scheduled as needed.</li> </ul>","tags":["EGR314","Team 305"]},{"location":"#contact-information","title":"Contact Information","text":"Name Primary Communication Method Secondary Communication Method Third Communication Method Agilan Kumar Discord Email Canvas Andrew Rushton Discord Email Canvas David Diaz Discord Email Canvas Zachary Romero Discord Email Canvas","tags":["EGR314","Team 305"]},{"location":"#conflict-resolution","title":"Conflict Resolution","text":"<ol> <li>Address disagreements promptly and respectfully.</li> <li>Escalate unresolved conflicts to the instructor for mediation.</li> <li>Foster a constructive and supportive team environment.</li> </ol>","tags":["EGR314","Team 305"]},{"location":"#project-overview-and-subsystems","title":"Project Overview and Subsystems","text":"","tags":["EGR314","Team 305"]},{"location":"#team-project-description","title":"Team Project Description","text":"<p>The team project aims to design a STEM-themed interactive display system for K-12 students. It will consist of the following modular subsystems:</p> <ol> <li> <p>Sensor Subsystem: Includes a sensor that communicates via I2C or SPI.</p> </li> <li> <p>Actuator Subsystem: Includes an actuator for bidirectional control and response.</p> </li> <li> <p>HMI Subsystem: Implements push buttons and an OLED screen for user interaction.</p> </li> <li> <p>Communication Subsystem: Ensures reliable UART communication and MQTT-based IoT connectivity.</p> </li> </ol>","tags":["EGR314","Team 305"]},{"location":"#individual-contributions","title":"Individual Contributions:","text":"<ul> <li>Each teammate will design and build their subsystem, including:</li> <li>Block diagram, schematic, and PCB layout.</li> <li>Software and API for UART communication.</li> <li>Datasheet with detailed documentation.</li> </ul>","tags":["EGR314","Team 305"]},{"location":"#appendix","title":"Appendix","text":"","tags":["EGR314","Team 305"]},{"location":"#supporting-notes","title":"Supporting Notes:","text":"<ul> <li>Team members will rotate roles bi-weekly to share responsibilities.</li> <li>Additional communication channels (Slack, Zoom) will be used if needed.</li> <li>Unused team notes or steps will be archived here for future reference.</li> </ul>","tags":["EGR314","Team 305"]},{"location":"#links-to-individual-datasheets","title":"Links to Individual Datasheets:","text":"<ul> <li>Agilan Kumar's Datasheet</li> <li>Andrew Rushton's Datasheet</li> <li>David Diaz's Datasheet</li> <li>Zachary Romero's Datasheet</li> </ul>","tags":["EGR314","Team 305"]},{"location":"#conclusion","title":"Conclusion","text":"<p>We are excited to work as a team to create an innovative and impactful STEM-themed project for the EGR314 Innovation Showcase. With a strong focus on modularity, collaboration, and professionalism, we aim to deliver a project that exceeds expectations and inspires future STEM learners.</p>","tags":["EGR314","Team 305"]},{"location":"1-ideation/","title":"Project Ideation and Concept Generation","text":""},{"location":"1-ideation/#overview","title":"Overview","text":""},{"location":"1-ideation/#introduction","title":"Introduction","text":"<p>Our team recognized the importance of thoroughly understanding our challenge before diving into solutions. We needed to clearly define the goal of our exhibit\u2014what message or concept we wanted to communicate\u2014and identify who our audience would be. These foundational steps were critical to ensure that our efforts aligned with the needs and expectations of the visitors we aimed to engage. By focusing on fostering curiosity, learning, and meaningful interactions, we set the stage for designing an exhibit that could leave a lasting impression.</p> <p>To move forward, we initiated a brainstorming session to generate potential solutions and features for our exhibit. Drawing inspiration from best practices in interactive exhibit design, we considered factors like intuitive controls, safety, accessibility, and engagement. Our goal was to explore a wide variety of ideas, encourage creativity, and develop concepts that could address both the needs of our audience and the unique challenges presented by our project. Through this process, we aimed to identify innovative and practical solutions to bring our vision to life.</p>"},{"location":"1-ideation/#understanding-the-exhibit","title":"Understanding the Exhibit","text":"<p>Our exhibit aims to create an engaging, hands-on learning experience that allows visitors to explore fundamental STEM concepts interactively. The goal is to inspire curiosity and critical thinking by providing an intuitive, user-friendly experience that encourages visitors to experiment and understand key scientific principles. Through interactive demonstrations, we strive to bridge the gap between theoretical knowledge and real-world applications, making learning both fun and educational.</p> <p>Our primary audience includes K-12 students, educators, and families seeking to enhance their understanding of STEM concepts through interactive exhibits. The design of our exhibit takes into consideration factors such as varying age groups, cognitive abilities, and accessibility needs. For younger audiences, the interface will be simple and visually engaging, while older students and educators will benefit from deeper insights and advanced features. Ensuring safety, durability, and inclusivity is paramount, allowing all visitors to participate and gain meaningful insights from the experience.</p>"},{"location":"1-ideation/#brainstorming-process","title":"Brainstorming Process","text":"<p>Our brainstorming sessions were structured to foster creativity and collaboration while addressing the diverse challenges of designing an effective and engaging exhibit. We utilized Lucidchart as a tool for documenting and organizing ideas in real-time. Through a series of structured sessions, we explored various aspects of the project to ensure a thorough and impactful ideation process. The key components of our approach included:</p> <ul> <li> <p>Brainstorming sessions: Team members were encouraged to freely contribute ideas in a judgment-free and collaborative environment. We focused on generating a wide range of ideas, prioritizing quantity over quality during the initial phase to ensure unconventional and innovative concepts were considered.</p> </li> <li> <p>SWOT analysis: Each idea was evaluated using a framework to identify its strengths, weaknesses, opportunities, and threats. This process helped us refine our focus and prioritize ideas that were both practical and impactful.</p> </li> <li> <p>Prototyping and feedback loops: Rough prototypes were developed for selected concepts, and iterative feedback was collected. This allowed us to improve and refine ideas based on functionality, feasibility, and user engagement.</p> </li> </ul> <p>To begin the brainstorming process, we first discussed the major features and systems that would make our project both educational for the audience and a valuable learning experience for our team. From these discussions, we identified the need for multiple systems incorporating sensors, actuators, and human-machine interfaces (HMI). In addition, we emphasized the importance of safety and durability, instructional aids for better learning, and interactivity features to accommodate audiences with diverse abilities.</p> <p></p>      Figure 1.1: Organized Ideas   <p> As a result, we aimed to generate at least 100 ideas covering the key areas of sensors, actuators, controls, and interactive features. This comprehensive approach helped us lay the foundation for a modular, user-friendly project design that could be further refined during the subsequent steps. </p> <p></p>      Figure 1.2: Early Unorganized Brainstorming Results   <p> After that we sorted all of the ideas into the categories that they fit best in. </p> <p></p>      Figure 1.3: Mid Organized Brainstorming Results   <p> Finally we decided which ideas were most important to us and put stars on them. </p> <p></p>      Figure 1.4: Final Organized Brainstorming Results"},{"location":"1-ideation/#sorted-and-ranked-ideas","title":"Sorted and Ranked Ideas","text":"<p>After completing the brainstorming process, we organized and refined the ideas to identify the most impactful and cohesive concepts for our project. The ideas were grouped into four main categories\u2014Sensors, Actuators, Controls (HMI), and Interactivity Features. Each category was further analyzed to select the top ideas based on feasibility, educational value, and audience engagement.</p>"},{"location":"1-ideation/#sensors","title":"Sensors","text":"<ol> <li>Analog temperature sensor with amplification for real-time weather monitoring.</li> <li>Pressure sensor to measure airflow changes in a Bernoulli Effect demonstration.</li> <li>Ultrasonic sensor to detect distances for precise measurements.</li> <li>Light sensor to measure ambient brightness for dynamic lighting systems.</li> <li>Microphone to capture sound for audio visualization projects.</li> </ol>"},{"location":"1-ideation/#actuators","title":"Actuators","text":"<ol> <li>Adjustable fan to simulate airflow in weather or fluid dynamics experiments.</li> <li>Brushed DC motor to enable movement in robotic systems.</li> <li>Stepper motor for precise control in self-balancing robots or visual demonstrations.</li> <li>LED matrix for dynamic data visualization and engaging displays.</li> <li>Vibrating motor to provide tactile feedback in interactive systems.</li> </ol>"},{"location":"1-ideation/#controls-hmi","title":"Controls (HMI)","text":"<ol> <li>OLED screen to display real-time data and visual feedback.</li> <li>Buttons to adjust speed, brightness, or other system parameters.</li> <li>Joystick for controlling robotic movements or interactive inputs.</li> <li>Gesture recognition sensor for touchless control of the system.</li> <li>Voice commands for hands-free interaction with the exhibit.</li> </ol>"},{"location":"1-ideation/#interactivity-features","title":"Interactivity Features","text":"<ol> <li>Levitation demonstration using airflow to engage users in fluid dynamics.</li> <li>Dynamic LED patterns that react to sound or user inputs.</li> <li>Real-time graphing of sensor data on a display for educational purposes.</li> <li>Adjustable weather simulation with temperature and airflow changes.</li> <li>Reaction timer to measure and display user response times.</li> </ol>"},{"location":"1-ideation/#key-findings","title":"Key Findings","text":"<p>From our brainstorming and analysis, the following ideas emerged as practical, impactful, and aligned with the goals of the project:</p> <p>Bernoulli Effect Demonstrator</p> <ul> <li> <p>Concept: A hands-on exhibit where visitors can adjust airflow using fans and observe how objects like ping-pong balls levitate.</p> </li> <li> <p>Audience Impact: Engages visitors by visualizing fluid dynamics in a fun, interactive way.</p> </li> </ul> <p>Simple Weather Station</p> <ul> <li> <p>Concept: A device that measures temperature, humidity, and light levels, with real-time display and internet connectivity.</p> </li> <li> <p>Audience Impact: Helps students understand environmental monitoring and weather data through live sensor feedback and actuation.</p> </li> </ul> <p>Self-Balancing Robot</p> <ul> <li> <p>Concept: A robot that uses gyroscopes and motors to balance on two wheels, teaching feedback loops and stability.</p> </li> <li> <p>Audience Impact: Demonstrates control systems in robotics, with options for user adjustments via a phone app.</p> </li> </ul> <p>Line-Following Robot</p> <ul> <li> <p>Concept: A robot that follows a drawn line on a surface, teaching pathfinding algorithms and sensor use.</p> </li> <li> <p>Audience Impact: Simple to operate and visually engaging, allowing students to experiment with paths.</p> </li> </ul> <p>Interactive LED Sound Visualizer</p> <ul> <li> <p>Concept: A sound-activated LED matrix that displays patterns and waveforms based on sound input, visualizing the properties of sound waves.</p> </li> <li> <p>Audience Impact: Combines audio and visuals to create an immersive STEM learning experience, teaching about frequency, amplitude, and waveforms.</p> </li> </ul>"},{"location":"1-ideation/#final-design-concept","title":"Final Design Concept","text":"<p>Figure 1.6: Final Design Concept</p> <p>Our concept sketch is of a line following a robot designed to teach museum visitors about pathfinding algorithms and sensor functionality. This concept satisfies all the needs of the museum visitors by offering an engaging and hands-on learning experience. The robot\u2019s ability to follow a line demonstrates the real-world application of sensor-based navigation, similar to autonomous cars. Visitors will gain insights into how the sensors detect and respond to the environment and how the algorithm processes the data to make decisions. The interactive nature of this device is very user-friendly and easy to use for all ages. </p> <p>Science Exhibits Readings Summary: Clear instruction labels make the device intuitive and educational. We will provide easy-to-read instruction labels for the visitors to easily use and understand.  As far as controls it will be fairly simple since the algorithm requires the visitor to draw a line and the robot will follow.  The robot will be made to be durable since many visitors will be using it and the device needs to be able to last for long periods.  We will provide a very detailed instruction label on the device and make sure it is clear to read so no error can be made during use.</p> <p>Our project will be split into four main components:  1. The first will be the output screen, which will display the real-time camera view of the robot to further teach the concepts of how the software functions and what the machine is doing. The screen will also function as a controller for the robot, allowing you to power it off and change certain settings.  1. The second will be the wireless connection between the robot and the screen, which will be an internet-based two-way communication.  1. The third component will be the camera sensor and the coding behind the visual detection as well as the position calculation.  1. The fourth and final will be the motor controls as well as handling input data from the sensors.</p>"},{"location":"1-ideation/#conclusion","title":"Conclusion","text":"<p>The goal of the project is to provide a device that can help teach students all types of sciences and give them a head start if they are heading toward the engineering route. We are supposed to create an impact on the audience and help them engage in a STEM learning experience. The brainstorming of the devices that could help engage students can help show them a wide variety of STEM-related topics. The topics can range from understanding science topics better to a headstart toward robotics, and many other topics. These devices will also be very engaging so that users can easily figure out how they work. The goal is to provide a learning experience more than anything and help the user better understand the topic they are learning. As for the future</p>"},{"location":"2-Block-Diagram/","title":"Block Diagram, Process Diagram, and Message Structure","text":""},{"location":"2-Block-Diagram/#block-diagram","title":"Block Diagram","text":"<p>In designing our system's block diagram, we followed a logical, event-driven flow that aligned with the functional goals of our project. The decision to structure the diagram starting with the Sensor, followed by WiFi (MQTT server communication), then the Motors, and finally the HMI, was based on the natural progression of how data flows through the system and how each component responds to that data. The color sensor is the initiating element\u2014it detects environmental input (red or blue light), which then triggers the rest of the system. Once a color is detected, that data needs to be communicated to the server, which is done through the WiFi module using MQTT protocol. This communication layer is central to decision-making and bridges the sensor input with system-wide actions.</p> <p>From there, the MQTT server interprets the color data and sends specific commands to the motor system to control its motion. The motor, in turn, operates based on this command and measures its own speed data. Finally, this feedback is sent to the HMI, where users can observe system performance in real time. By following this Sensor \u2192 WiFi \u2192 Motors \u2192 HMI structure, our block diagram clearly represents the sequential interaction between subsystems and how information flows from input to action to feedback. This design ensures clarity, supports modular testing, and meets the product requirements for reliable detection, responsive actuation, real-time communication, and user interface feedback.</p> <p>Block Diagram PDF</p>"},{"location":"2-Block-Diagram/#final-communication-sequence","title":"Final Communication Sequence","text":"<p>Our communication sequence diagram was structured to reflect the modular, distributed design of our system, ensuring each component could operate independently while communicating effectively through UART. The flow starts with the Color Sensor, which detects whether a red or blue color is present. This decision to place the sensor at the start of the sequence reflects its role as the system\u2019s input trigger, satisfying the core requirement that the robot react to color-based environmental changes.</p> <p>Once the sensor detects a color, it sends that data to the ESP32, which serves as the WiFi module and gateway to the MQTT server. This step allows for real-time data storage and centralized decision-making, which is critical for remote monitoring and command dispatch. Based on the received color data, the MQTT server sends a control message back through the ESP32 to the PIC microcontroller, which interprets the instruction and sends appropriate signals to the motor driver via SPI. This enables the robot to physically respond to the detected color, aligning with user expectations for immediate, visible feedback.</p> <p>Finally, the PIC collects motor speed data and sends it back to the ESP32 using UART. The ESP32 then updates the HMI interface, showing current motor behavior and sensor results. This full-loop feedback satisfies the user requirement for real-time visibility into the system\u2019s operation. By sequencing our diagram in the order of Sensor \u2192 WiFi \u2192 Motors \u2192 HMI, we ensure that data flows logically from perception to action to feedback, delivering a clear and traceable experience for the user while fulfilling all outlined product functionalities.</p>"},{"location":"2-Block-Diagram/#1-user-powers-on-the-system","title":"1. User Powers On the System","text":"<ul> <li>Each microcontroller (Sensor, HMI, Motor, MQTT) powers on individually.  </li> <li>Subsystems begin listening on UART and prepare for message exchange.</li> </ul>"},{"location":"2-Block-Diagram/#2-sensor-subsystem-monitors-for-color","title":"2. Sensor Subsystem Monitors for Color","text":"<ul> <li>The Sensor ESP32 continuously polls the I2C color sensor.  </li> <li>When it detects red or blue, it determines a stop event has occurred.  </li> <li>It sends a 5-byte stop message (<code>0x64</code> or <code>0x65</code>) over UART.</li> </ul>"},{"location":"2-Block-Diagram/#3-uart-message-reaches-the-mqtt-subsystem","title":"3. UART Message Reaches the MQTT Subsystem","text":"<ul> <li>The MQTT ESP32 receives the message, verifies its structure, and detects it as a valid stop trigger.  </li> <li>MQTT logs the event and initiates a lockout period to prevent redundant triggers.  </li> <li>MQTT sends a standardized stop command (<code>0x00</code>) over UART to the motor system and publishes <code>car/state = 0</code> to MQTT.</li> </ul>"},{"location":"2-Block-Diagram/#4-mqtt-triggers-a-timed-restart","title":"4. MQTT Triggers a Timed Restart","text":"<ul> <li>After a 5-second stop period, the MQTT system sends a go message (<code>0x01</code>) over UART.  </li> <li>It also publishes <code>car/state = 1</code> to the MQTT broker.  </li> <li>This ensures coordinated restart of movement.</li> </ul>"},{"location":"2-Block-Diagram/#5-hmi-receives-and-displays-movement-status","title":"5. HMI Receives and Displays Movement Status","text":"<ul> <li>The HMI ESP32 listens over UART for stop (<code>0x00</code>) or go (<code>0x01</code>) messages.  </li> <li>It updates its OLED display with a large X (stop) or upward arrow (go).  </li> <li>It also subscribes to <code>car/state</code> over MQTT as a fallback if UART fails.</li> </ul>"},{"location":"2-Block-Diagram/#6-sensor-fallback-if-uart-to-hmi-fails","title":"6. Sensor Fallback if UART to HMI Fails","text":"<ul> <li>If no UART messages are received from the HMI after 15 seconds, the Sensor board enables MQTT fallback mode.  </li> <li>It listens for relayed messages from the HMI over MQTT and continues normal operation.</li> </ul>"},{"location":"2-Block-Diagram/#7-mqtt-logs-system-behavior","title":"7. MQTT Logs System Behavior","text":"<ul> <li>The MQTT system tracks terminated and filtered messages.  </li> <li>It publishes data to the broker for analysis (e.g., <code>counter/terminated</code>, <code>counter/redundant</code>).  </li> <li>A Python script running on the local computer visualizes this in real time via Matplotlib.</li> </ul>"},{"location":"2-Block-Diagram/#message-structure-and-design-process","title":"Message Structure and Design Process","text":"<p>Our team designed a 5-byte UART message structure consisting of a Start Byte, Sender ID, Receiver ID, Data Byte, and End Byte. This provided a consistent framework for message formatting and error checking across subsystems. The original intent was to use the Sender and Receiver IDs for targeted delivery and basic validation, but as our system evolved, we began to use these fields in more flexible and functional ways.</p> <p>Most notably, we implemented a system-wide method of detecting when a message had already traveled around the entire UART chain. When a message was first received by the MQTT system, we altered its Receiver byte from its original value to <code>0x04</code>. Since all messages pass through each board in the UART loop, when a board later received a message already tagged with <code>Receiver = 0x04</code>, we could safely assume it had completed one full trip through the network and could now be terminated. This mechanism provided a simple but robust way to eliminate redundant or looping messages without the need for message tracking or UUIDs, simplifying the logic for all subsystems.</p>"},{"location":"2-Block-Diagram/#top-5-software-design-changes","title":"Top 5 Software Design Changes","text":"<ol> <li> <p>MQTT Backup System    Initially, we designed the system to rely solely on UART for communication. However, as we progressed, we implemented a robust MQTT backup that activates if a UART timeout occurs on the Sensor subsystem. When UART fails, the Sensor subscribes to the HMI's MQTT topic and resumes communication via MQTT instead of UART. This fallback system ensured our communication architecture remained functional and resilient even during partial subsystem failures.</p> </li> <li> <p>Repeat Message Filtering + Graph Output    We added logic to filter repeated stop messages at the MQTT system level, preventing the car from being retriggered by redundant sensor input. A 2-second lockout followed each valid stop event. We also tracked the number of filtered messages and exposed that information through MQTT topics so that a Python-based local graphing utility could visualize system behavior in real time. This gave us a powerful debugging and feedback mechanism for observing system stability and message traffic.</p> </li> <li> <p>Receiver ID Modification for Message Termination    We added a mechanism in the MQTT subsystem to change the Receiver ID of a message to <code>0x04</code> once it had been processed. When any subsystem later receives a message with <code>Receiver = 0x04</code>, it knows that message has already traveled through the system once and terminates it instead of forwarding. This design change allowed us to eliminate message loops without requiring per-board message history tracking and helped the MQTT system act as a central filter without additional memory overhead.</p> </li> <li> <p>Message Simplification    Originally, we used separate messages to indicate each type of stop or color trigger. We simplified this into a streamlined structure where the sensor sends either <code>0x64</code> or <code>0x65</code> for red or blue, both of which are treated identically as stop commands. The MQTT system receives this, then sends a <code>0x00</code> message down the line to stop the car, waits for a timer to expire, and sends a <code>0x01</code> to resume movement. This design simplified downstream logic and centralized stop/go timing into the MQTT system, improving consistency and reliability.</p> </li> <li> <p>HMI Simplification    Our original plan for the HMI system involved displaying detailed information based on incoming UART messages, such as color, sender ID, or command type. However, we found this to be unnecessarily complex for the role of the HMI, which was simply to provide a clear visual indicator of the car\u2019s current state. We simplified the HMI logic so that it only reacts to two command values: <code>0x00</code> to indicate stop and <code>0x01</code> to indicate go. This not only made the code more concise and reliable but also aligned better with our standardized message structure and reduced the risk of display errors due to unexpected message content.</p> </li> </ol>"},{"location":"2-Block-Diagram/#communication-protocols-used","title":"Communication Protocols Used","text":"<ul> <li>I2C Communication \u2192 Used between the ESP32 and Color Sensor for real-time data exchange and control.  </li> <li>SPI Signals \u2192 Used internally within the Motor Driver to control motor speed and direction based on PIC commands.  </li> <li>UART Communication \u2192 Used for debugging and communication between systems.  </li> </ul> <pre><code>sequenceDiagram\n    autonumber\n    participant User\n    participant HMI as Agilan (ESP32 - HMI - SPI)\n    participant David as David (ESP32 - Color Sensor - I2C)\n    participant Andrew as Andrew (ESP32 - Wifi Connectivity - MQTT)\n    participant Zack as Zack (PIC18 - Motor Driver - SPI)\n\n\n    User-&gt;&gt;HMI: Start Line-Following Mode\n    HMI-&gt;&gt;David: Record Line Color Data (I2C)\n    David-&gt;&gt;Andrew: Send Color Data\n    Andrew-&gt;&gt;Zack: Send Movement Command\n    Zack--&gt;&gt;HMI: Send Robot Status\n    HMI--&gt;&gt;User: Display Robot Progress</code></pre>"},{"location":"2-Block-Diagram/#message-structure-diagram","title":"Message Structure Diagram","text":""},{"location":"2-Block-Diagram/#sensor-sends-stop-command-to-mqtt","title":"Sensor Sends Stop Command to MQTT","text":"<ul> <li>When the Sensor ESP32 detects red or blue, it sends a stop message over UART.</li> <li>Message format: <code>[0x41 | Source: 0x01 (Sensor) | Destination: 0x04 (MQTT) | Data: 0x64 or 0x65 | 0x42]</code></li> </ul>"},{"location":"2-Block-Diagram/#mqtt-relays-command-to-motor-system","title":"MQTT Relays Command to Motor System","text":"<ul> <li>The MQTT ESP32 validates the message and enters a lockout period.</li> <li>It sends a stop command to the Motor subsystem.</li> <li>Message format: <code>[0x41 | Source: 0x04 (MQTT) | Destination: 0x05 (Motor) | Data: 0x00 | 0x42]</code></li> </ul>"},{"location":"2-Block-Diagram/#mqtt-sends-timed-go-command","title":"MQTT Sends Timed Go Command","text":"<ul> <li>After the stop period ends, the MQTT subsystem sends a go command.</li> <li>Message format: <code>[0x41 | Source: 0x04 (MQTT) | Destination: 0x05 (Motor) | Data: 0x01 | 0x42]</code></li> </ul>"},{"location":"2-Block-Diagram/#mqtt-rewrites-receiver-for-loop-detection","title":"MQTT Rewrites Receiver for Loop Detection","text":"<ul> <li>When MQTT receives a valid message not intended for itself, it modifies the receiver byte to 0x04 before forwarding.</li> <li>This marks that the message has looped through the system once and allows MQTT to terminate it if seen again.</li> <li>Original message: <code>[0x41 | Source: 0x03 | Destination: 0x05 | Data: X | 0x42]</code>   Forwarded message: <code>[0x41 | Source: 0x03 | Destination: 0x04 | Data: X | 0x42]</code></li> </ul>"},{"location":"2-Block-Diagram/#hmi-displays-state-based-on-uart","title":"HMI Displays State Based on UART","text":"<ul> <li>The HMI ESP32 receives messages from MQTT via UART and updates the OLED display.</li> <li>Message format: <code>[0x41 | Source: 0x04 (MQTT) | Destination: 0x03 (HMI) | Data: 0x00 or 0x01 | 0x42]</code></li> </ul>"},{"location":"2-Block-Diagram/#mqtt-publishes-state-to-mqtt-broker","title":"MQTT Publishes State to MQTT Broker","text":"<ul> <li>MQTT also publishes state updates to the broker for remote visualization and fallback usage.</li> <li>Topics and values include:</li> <li><code>car/state</code>: <code>\"0\"</code> (stop) or <code>\"1\"</code> (go)</li> <li><code>counter/terminated</code>: Number of terminated messages</li> <li><code>counter/redundant</code>: Number of filtered repeated messages</li> </ul>"},{"location":"2-Block-Diagram/#sensor-fallback-uses-mqtt-to-receive-messages","title":"Sensor Fallback Uses MQTT to Receive Messages","text":"<ul> <li>If UART communication with the HMI fails, the Sensor switches to fallback mode and receives control messages from MQTT.</li> <li>Fallback message example: <code>[0x41 | Source: 0x03 (HMI) | Destination: 0x01 (Sensor) | Data: 0x00 or 0x01 | 0x42]</code></li> </ul>"},{"location":"2-Block-Diagram/#the-system-loops-continuously","title":"The System Loops Continuously","text":"<ul> <li>The Sensor continues monitoring for color.</li> <li>MQTT coordinates message flow and filtering.</li> <li>HMI reflects current movement status.</li> </ul>"},{"location":"2-Block-Diagram/#sequencediagram-autonumber-participant-user-participant-esp32hmi-participant-esp32sensor-participant-color-sensor-participant-pic18lf26k22-participant-motor-driver-participant-esp32wifi-esp32hmi-esp32sensor-wake-up-esp32sensor-color-sensor-request-line-color-data-0x41-esp32-sensor-read-color-0x42-color-sensor-esp32sensor-send-line-color-data-0x41-sensor-esp32-color-value-0x42-esp32sensor-pic18lf26k22-send-movement-request-0x41-esp32-pic18-color-value-0x42-pic18lf26k22-motor-driver-adjust-speed-0x41-esp32-motor-speed-value-0x42-motor-driver-pic18lf26k22-confirm-speed-update-0x41-motor-pic18-speed-ack-0x42-pic18lf26k22-esp32wifi-send-speedmovement-data-0x41-motor-esp32-speed-ack-0x42-esp32wifi-esp32hmi-send-status-update-0x41-esp32-hmi-status-data-0x42-esp32hmi-user-display-robot-status","title":"<pre><code>sequenceDiagram\n    autonumber\n    participant USER\n    participant ESP32(HMI)\n    participant ESP32(Sensor)\n    participant Color Sensor\n    participant PIC18LF26K22\n    participant Motor Driver\n    participant ESP32(Wifi)\n\n    ESP32(HMI)-&gt;&gt;ESP32(Sensor): Wake Up\n    ESP32(Sensor)-&gt;&gt;Color Sensor: Request Line Color Data [0x41 | ESP32 | Sensor | Read Color | --- | 0x42]\n    Color Sensor--&gt;&gt;ESP32(Sensor): Send Line Color Data [0x41 | Sensor | ESP32 | Color Value | --- | 0x42]\n    ESP32(Sensor)-&gt;&gt;PIC18LF26K22: Send Movement Request [0x41 | ESP32 | PIC18 | Color Value | --- | 0x42]\n    PIC18LF26K22-&gt;&gt;Motor Driver: Adjust Speed [0x41 | ESP32 | Motor | Speed Value | --- | 0x42]\n    Motor Driver--&gt;&gt;PIC18LF26K22: Confirm Speed Update [0x41 | Motor | PIC18 | Speed Ack | --- | 0x42]\n    PIC18LF26K22-&gt;&gt;ESP32(Wifi): Send Speed/Movement Data [0x41 | Motor | ESP32 | Speed Ack | --- | 0x42]\n    ESP32(Wifi)-&gt;&gt;ESP32(HMI): Send Status Update [0x41 | ESP32 | HMI | Status Data | --- | 0x42]\n    ESP32(HMI)-&gt;&gt;USER: Display Robot Status</code></pre>","text":"<p>Enlarged Sequence Diagram</p>"},{"location":"3-Resources/","title":"Final Design/Team Code","text":""},{"location":"3-Resources/#overview","title":"Overview","text":"<p>Figure 1.1: A short video of our machine running and boards in place</p> <p> </p> <p></p> <p>Figure 2.1: Our final design for the body of our robot with all the boards inside</p> <p> </p> <p></p> <p>Figure 2.2: All of our boards connected creating communication through all subsystems</p> <p> </p>"},{"location":"3-Resources/#indvidual-codes-for-all-subsystems","title":"Indvidual Codes for all Subsystems","text":""},{"location":"3-Resources/#mqtt","title":"MQTT","text":"<ul> <li>Andrew's Code</li> </ul>"},{"location":"3-Resources/#color-sensor","title":"Color Sensor","text":"<ul> <li>David's Code</li> </ul>"},{"location":"3-Resources/#hmi","title":"HMI","text":"<ul> <li>Agilan's Code</li> </ul>"},{"location":"3-Resources/#motor-driver","title":"Motor Driver","text":"<ul> <li>Zachary's Code</li> </ul>"},{"location":"3-Resources/#solidworks-files","title":"SolidWorks Files","text":"<ul> <li>Robot Model Files</li> <li>CAD boardholder PDF</li> <li>CAD Body PDF </li> </ul>"},{"location":"4-Showcase%20Poster/","title":"Innovation Showcase Poster","text":"<p>\ud83d\udcc4 Download Full Team Poster PDF</p>"},{"location":"5-Reflection/","title":"Reflection","text":""},{"location":"5-Reflection/#what-we-learned","title":"What we learned","text":"<ul> <li>We learned that it is very difficult to get the ESP32 and PIC to communicate togther.</li> <li>Learning how to use micropython proficentally on VScode with the ESP32.</li> <li>Really understood how to read other codes.</li> <li>Learned how to integrate such subsystems like the mqtt, hmi, motors, and sensors.</li> <li>Learned why schematic organiation and PCB layout is important.</li> <li>How MQTT works for lightweight wireless communication between subsystems.</li> <li>How to simplify user interaction with the HMI subsystem.</li> <li>How to use UART communication to reliably send and recieve commands between subsystems.</li> <li>Why clear pin management and module planning is when working with microcontrollers like the PIC and ESP32.</li> <li>How working in a team enhances problem-solving, especially when integrating different subsystems, code, hardware, and mechanical design.</li> </ul>"},{"location":"5-Reflection/#future-recommendations-for-students","title":"Future Recommendations for Students","text":"<ul> <li>Make sure you define the right pins if you switch the pin layouts.</li> <li>Don't try to overcomplicate it with the code.</li> <li>Lectures in class are very helpful towards help for any of the subsystems.</li> <li>Do not fall behind on making schematics and PCBs, it is a team project.</li> <li>Go to office hours whenever needed, and always ask the TAs.</li> <li>Always try to checkup on your team just to make sure everyone is up to task.</li> </ul>"},{"location":"5-Reflection/#communication-architecture-version-20-reflection","title":"\ud83d\udce1Communication Architecture \u2013 Version 2.0 Reflection","text":"<p>In a Version 2.0 of our communication architecture, we would focus on improving reliability, modularity, and scalability of subsystem communication.</p>"},{"location":"5-Reflection/#potential-future-extensions","title":"Potential Future Extensions","text":"<p>Many of the improvements listed below are already present within the group\u2019s systems \u2014 including structured message protocols, modular code organization, and debugging support. The following suggestions reflect ways these existing features could be expanded, standardized across all subsystems, or enhanced for greater robustness in future iterations.</p>"},{"location":"5-Reflection/#structured-protocol-format","title":"Structured Protocol Format","text":"<p>The current system uses a consistent message structure (<code>Start | Sender | Receiver | Data | End</code>) for UART communication. This improves parsing, enables validation, and simplifies debugging.</p> <p>Future extension: Formalize message versioning or message type fields to support a wider range of command formats and features.</p>"},{"location":"5-Reflection/#modular-codebase","title":"Modular Codebase","text":"<p>Several subsystems separate functionality into clear modules, such as UART parsing, message logic, and application control. This modular approach improves maintainability and scalability.</p> <p>Future extension: Standardize this structure across all boards to streamline development, testing, and future integration of new components.</p>"},{"location":"5-Reflection/#enhanced-debugging","title":"Enhanced Debugging","text":"<p>Debugging tools \u2014 such as verbose logs, debug LEDs, and OLED indicators \u2014 are already used to track system behavior and communication states.</p> <p>Future extension: Incorporate timestamps, message counters, or structured debug outputs to make logs more informative and consistent.</p>"},{"location":"5-Reflection/#new-protocol-features","title":"New Protocol Features","text":"<p>Message filtering, repeat suppression, invalid message handling, and heartbeat monitoring have already been implemented in parts of the system.</p> <p>Future extension: Add ACK/NAK confirmation messages for critical commands, and define more structured error codes for invalid or incomplete messages.</p>"},{"location":"5-Reflection/#system-reliability","title":"System Reliability","text":"<p>Timers and lockout mechanisms are in place to avoid repeated stop signals and ensure message handling stability.</p> <p>Future extension: Adopt interrupt-based UART reception across all boards and use buffering or queuing strategies to improve responsiveness during high traffic.</p>"},{"location":"5-Reflection/#peripheral-expansion","title":"Peripheral Expansion","text":"<p>I2C communication is already implemented for the color sensor subsystem.</p> <p>Future extension: Expand support for other sensors (e.g., SPI-based), and consider structured handlers for interpreting more complex sensor data.</p>"},{"location":"5-Reflection/#why-these-changes","title":"Why These Changes?","text":"<p>These improvements would make the system more robust for future classroom projects, easier to debug and extend, and better suited for integration with additional subsystems such as distance sensing, autonomous navigation, or remote control modules.</p>"},{"location":"static/node_modules/mathjax/","title":"MathJax","text":""},{"location":"static/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"static/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"static/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"static/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"static/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"static/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"static/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\nloader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\nconst svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\nconsole.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"static/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"static/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"static/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"static/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"}]}